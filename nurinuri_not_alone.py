# nurinuri_not_alone.py
# ì‹¤í–‰: streamlit run nurinuri_not_alone.py
# requirements.txt ì°¸ê³ 

import streamlit as st
import pandas as pd
import numpy as np
import pydeck as pdk
import requests
from datetime import datetime, timedelta, time as dtime
from io import BytesIO
from zoneinfo import ZoneInfo
import os, json, re, base64, math

KST = ZoneInfo("Asia/Seoul")

# ------------------------
# íŒŒì¼ / ìƒìˆ˜
# ------------------------
CHECKIN_CSV = "checkins.csv"
MEDS_CSV = "meds.csv"
MEDLOG_CSV = "med_log.csv"
INSTITUTIONS_CSV = "institutions.csv"
REGIONAL_CSV = "regional_factors.csv"
HOME_JSON = "home_location.json"
CONTACTS_JSON = "contacts.json"

# ê°•ì•„ì§€ ì´ë¯¸ì§€ (ì‚¬ìš©ìê°€ ì¤€ URL ì‚¬ìš©)
DOG_URL_IDLE = "https://marketplace.canva.com/yKgYw/MAGz2eyKgYw/1/tl/canva-cartoon-illustration-of-a-happy-brown-poodle-MAGz2eyKgYw.png"
DOG_URL_SMILE = "https://image.utoimage.com/preview/cp861283/2024/09/202409012057_500.jpg"

# ------------------------
# ê°„ë‹¨ ì•½ë¬¼ ìƒí˜¸ì‘ìš© DB (ì˜ˆì‹œ, í•„ìš”í•œ ë§Œí¼ í™•ì¥ ê°€ëŠ¥)
# ------------------------
DRUG_INTERACTIONS = {
    "warfarin": ["ë¹„íƒ€ë¯¼Kê°€ í’ë¶€í•œ ìŒì‹(ì‹œê¸ˆì¹˜ ë“±)ê³¼ ìƒí˜¸ì‘ìš© ê°€ëŠ¥ â€” ë³µìš© ê·œì¹™ ì¤€ìˆ˜ í•„ìš”",
                 "NSAIDs(ì˜ˆ: ì´ë¶€í”„ë¡œíœ)ê³¼ í•¨ê»˜ ì“°ë©´ ì¶œí˜ˆ ìœ„í—˜ ì¦ê°€"],
    "atorvastatin": ["ê·¸ë ˆì´í”„í”„ë£¨íŠ¸ ì£¼ìŠ¤ëŠ” í˜ˆì¤‘ ë†ë„ ìƒìŠ¹ ê°€ëŠ¥ â€” í”¼í•˜ì„¸ìš”",
                     "ì¼ë¶€ í•­ìƒì œ(macrolide)ì™€ ë³‘ìš© ì‹œ ë¶€ì‘ìš© ì¦ê°€ ê°€ëŠ¥"],
    "simvastatin": ["ê·¸ë ˆì´í”„í”„ë£¨íŠ¸ ì£¼ìŠ¤ ê¸ˆê¸°", "ê°•ë ¥í•œ CYP3A4 ì–µì œì œì™€ ë³‘ìš© ì£¼ì˜"],
    "metformin": ["ê³¼ë„í•œ ìŒì£¼ ì‹œ ì –ì‚°ì‚°ì¦ ìœ„í—˜ ì¦ê°€ â€” ìŒì£¼ ì£¼ì˜"],
    "aspirin": ["ë‹¤ë¥¸ NSAIDsì™€ ë³‘ìš© ì‹œ ì¶œí˜ˆ ìœ„í—˜ ì¦ê°€", "í•­ì‘ê³ ì œ(ì™€íŒŒë¦° ë“±)ì™€ ë³‘ìš© ì£¼ì˜"],
    "amlodipine": ["ìëª½ê³¼ ìƒí˜¸ì‘ìš© ë³´ê³  ìˆìŒ â€” ì£¼ì˜"],
}

def lookup_interactions(drug_name: str):
    if not drug_name: return []
    name = str(drug_name).lower()
    warnings = []
    for k,v in DRUG_INTERACTIONS.items():
        if k in name or name in k:
            warnings += v
    tokens = re.split(r"[\s,/]+", name)
    for t in tokens:
        if t in DRUG_INTERACTIONS:
            warnings += DRUG_INTERACTIONS[t]
    # unique preserve order
    return list(dict.fromkeys(warnings))

# ------------------------
# ì˜¤ë””ì˜¤(ë‚´ì¥ í†¤) - ê²½ë³´ìš©
# ------------------------
def make_alarm_wav(seconds=1.2, freq=880, sr=16000):
    import wave, struct
    t = np.linspace(0, seconds, int(sr*seconds), False)
    tone = (0.5*np.sin(2*np.pi*freq*t)).astype(np.float32)
    buf = BytesIO()
    with wave.open(buf, 'wb') as w:
        w.setnchannels(1); w.setsampwidth(2); w.setframerate(sr)
        for s in tone:
            w.writeframes(struct.pack('<h', int(s*32767)))
    buf.seek(0)
    return buf.getvalue()

ALARM_WAV = make_alarm_wav()
ALARM_B64 = base64.b64encode(ALARM_WAV).decode()

# ------------------------
# ìœ í‹¸ í•¨ìˆ˜
# ------------------------
def now_kst():
    return datetime.now(KST)

def ensure_csv(path, cols):
    if not os.path.exists(path):
        pd.DataFrame(columns=cols).to_csv(path, index=False)

def save_csv(df, path):
    try:
        df.to_csv(path, index=False)
    except Exception:
        pass

def read_csv_flexible(path_or_buf):
    """í•œê¸€ CSV ì¸ì½”ë”©(utf-8-sig/CP949/EUC-KR/utf-8) ìë™ ì‹œë„"""
    encs = ["utf-8-sig", "cp949", "euc-kr", "utf-8", "latin1"]
    last_err = None
    # path_or_buf may be path string or an uploaded buffer
    if isinstance(path_or_buf, str):
        for e in encs:
            try:
                return pd.read_csv(path_or_buf, encoding=e)
            except Exception as err:
                last_err = err
                continue
        raise last_err
    else:
        raw = path_or_buf.read()
        for e in encs:
            try:
                return pd.read_csv(BytesIO(raw), encoding=e)
            except Exception:
                continue
        return pd.read_csv(BytesIO(raw))

def safe_read_csv(uploaded_or_path):
    return read_csv_flexible(uploaded_or_path)

def parse_time_str(tstr):
    try:
        h,m = map(int, str(tstr).split(":"))
        return dtime(hour=h, minute=m)
    except Exception:
        return None

def haversine_km(lat1, lon1, lat2, lon2):
    R = 6371.0
    phi1, phi2 = np.radians(lat1), np.radians(lat2)
    dphi = np.radians(lat2-lat1); dlambda = np.radians(lon2-lon1)
    a = np.sin(dphi/2.0)**2 + np.cos(phi1)*np.cos(phi2)*np.sin(dlambda/2.0)**2
    return 2*R*np.arcsin(np.sqrt(a))

def load_home():
    if os.path.exists(HOME_JSON):
        try:
            with open(HOME_JSON, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            return None
    return None

def save_home(lat, lon, label="ìš°ë¦¬ ì§‘"):
    try:
        with open(HOME_JSON, "w", encoding="utf-8") as f:
            json.dump({"label": label, "lat": float(lat), "lon": float(lon)}, f, ensure_ascii=False)
        return True
    except Exception:
        return False

def load_contacts():
    if os.path.exists(CONTACTS_JSON):
        try:
            with open(CONTACTS_JSON, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            return []
    return []

def save_contacts(lst):
    try:
        with open(CONTACTS_JSON, "w", encoding="utf-8") as f:
            json.dump(lst, f, ensure_ascii=False)
    except Exception:
        pass

# ------------------------
# ì²´í¬ì¸/ì‹œê°„ ì²˜ë¦¬/ìœ„í—˜ë„ ë¡œì§ (ì¹œêµ¬ ì½”ë“œ ê¸°ë°˜ ë³´ì¡´ ë° ê°œì„ )
# ------------------------
def ensure_timestamp(df: pd.DataFrame) -> pd.DataFrame:
    if "timestamp" in df.columns:
        df["timestamp"] = pd.to_datetime(df["timestamp"], errors="coerce")
        # localize naive datetimes to KST if tz-naive
        try:
            naive = df["timestamp"].dt.tz is None
        except Exception:
            naive = True
        # try to localize only naive
        def localize_try(ts):
            if pd.isna(ts):
                return pd.NaT
            if ts.tzinfo is None:
                try:
                    return ts.replace(tzinfo=KST)
                except Exception:
                    return ts
            return ts
        df["timestamp"] = df["timestamp"].apply(localize_try)
        df = df[pd.notna(df["timestamp"])]
    return df

def checkin_stats(df: pd.DataFrame, lookback_days=30):
    df = ensure_timestamp(df.copy())
    if df.empty:
        return {"missing_days": [], "z_outliers_idx": [], "mean_min": None, "std_min": None}
    df_recent = df[df["timestamp"] >= (now_kst() - timedelta(days=lookback_days))]
    if df_recent.empty:
        return {"missing_days": [], "z_outliers_idx": [], "mean_min": None, "std_min": None}
    daily = (df_recent
             .assign(date=lambda x: x["timestamp"].dt.date,
                     minutes=lambda x: x["timestamp"].dt.hour*60 + x["timestamp"].dt.minute)
             .sort_values("timestamp")
             .groupby("date", as_index=False).first())
    days = [(now_kst().date() - timedelta(days=i)) for i in range(lookback_days)]
    existing = set(daily["date"].tolist())
    missing = [d for d in days if d not in existing]
    if len(daily) >= 5:
        mins = daily["minutes"].to_numpy()
        mu = float(np.mean(mins))
        sd = float(np.std(mins)) if np.std(mins) > 0 else 1.0
        zscores = (mins - mu) / sd
        out_idx = list(np.where(np.abs(zscores) > 2)[0])
        return {"missing_days": missing, "z_outliers_idx": out_idx, "mean_min": mu, "std_min": sd, "daily": daily}
    return {"missing_days": missing, "z_outliers_idx": [], "mean_min": None, "std_min": None, "daily": daily}

def enumerate_due_times(start_clock: dtime, interval_hours: int, from_dt: datetime, to_dt: datetime):
    start_at = datetime.combine(from_dt.date(), start_clock, tzinfo=KST)
    while start_at > from_dt:
        start_at -= timedelta(hours=interval_hours)
    while start_at + timedelta(hours=interval_hours) < from_dt:
        start_at += timedelta(hours=interval_hours)
    times, cur = [], start_at
    while cur <= to_dt:
        if cur >= from_dt: times.append(cur)
        cur += timedelta(hours=interval_hours)
    return times

def estimate_adherence(meds_df, med_log_df, days=7, window_minutes=60):
    to_dt = now_kst(); from_dt = to_dt - timedelta(days=days)
    due_list = []
    taken_list = med_log_df[(pd.to_datetime(med_log_df["taken_at"])>=from_dt) & (pd.to_datetime(med_log_df["taken_at"])<=to_dt)].copy()
    for _, row in meds_df.iterrows():
        name = row["name"]; iv = int(row["interval_hours"]); sc = parse_time_str(str(row["start_time"]))
        if not sc: continue
        for d in enumerate_due_times(sc, iv, from_dt, to_dt):
            due_list.append({"name": name, "due_time": d})
    due_df = pd.DataFrame(due_list)
    if due_df.empty: return 0, 0
    taken_on_time, window = 0, timedelta(minutes=window_minutes)
    for _, due in due_df.iterrows():
        name = due["name"]; dtime_ = due["due_time"]
        cand = taken_list[(taken_list["name"]==name) & (pd.to_datetime(taken_list["taken_at"]).between(dtime_-window, dtime_+window))]
        if len(cand):
            taken_on_time += 1
            taken_list = taken_list.drop(cand.index[0])
    return len(due_df), taken_on_time

def already_taken(med_log_df, name, due_time, window_minutes=60):
    w = timedelta(minutes=window_minutes)
    hit = med_log_df[(med_log_df["name"]==name) & (pd.to_datetime(med_log_df["taken_at"]).between(due_time-w, due_time+w))]
    return len(hit) > 0

def due_now_list(meds_df, med_log_df, within_minutes=15, overdue_minutes=90):
    now = now_kst(); due_items = []
    for _, row in meds_df.iterrows():
        name = row["name"]; iv = int(row["interval_hours"]); sc = parse_time_str(str(row["start_time"]))
        if not sc: continue
        dues = enumerate_due_times(sc, iv, now - timedelta(days=2), now + timedelta(days=1))
        if not dues: continue
        closest = min(dues, key=lambda d: abs((d - now).total_seconds()))
        diff_min = (closest - now).total_seconds()/60.0
        status = None
        if abs(diff_min) <= within_minutes:
            status = "due"
        elif diff_min < 0 and abs(diff_min) <= overdue_minutes:
            status = "overdue"
        if status and not already_taken(med_log_df, name, closest, window_minutes=60):
            due_items.append({"name": name, "due_time": closest, "status": status})
    return due_items

def risk_score(checkins_df, med_log_df, meds_df):
    cs = checkin_stats(checkins_df, lookback_days=14)
    missing_last3 = [d for d in cs.get("missing_days", []) if (now_kst().date() - d).days <= 3]
    n_missing3 = len(missing_last3); n_out7 = 0
    if "daily" in cs and len(cs["daily"])>0 and cs.get("mean_min") is not None and cs.get("std_min",0)>0:
        last7 = cs["daily"][cs["daily"]["date"] >= (now_kst().date()-timedelta(days=7))]
        if len(last7) >= 5:
            mins = last7["minutes"].to_numpy()
            z = (mins - cs["mean_min"]) / cs["std_min"]
            n_out7 = int(np.sum(np.abs(z)>2))
    adherence = 1.0
    if not meds_df.empty:
        due_total, taken_on_time = estimate_adherence(meds_df, med_log_df, days=7, window_minutes=60)
        adherence = (taken_on_time / due_total) if due_total>0 else 1.0
    score = min(n_missing3, 3)/3*40 + min(n_out7, 5)/5*20 + (1.0 - adherence)*40
    return round(max(0, min(100, score)), 1), {
        "missing_last3": n_missing3, "outliers_last7": n_out7, "adherence_7d": round(adherence*100,1)
    }

# ------------------------
# ì´ˆê¸° íŒŒì¼ ìƒì„± / ë¡œë“œ
# ------------------------
ensure_csv(CHECKIN_CSV, ["timestamp","lat","lon"])
ensure_csv(MEDS_CSV, ["name","interval_hours","start_time","notes"])
ensure_csv(MEDLOG_CSV, ["name","due_time","taken_at"])
ensure_csv(INSTITUTIONS_CSV, [])
ensure_csv(REGIONAL_CSV, [])

checkins = pd.read_csv(CHECKIN_CSV) if os.path.exists(CHECKIN_CSV) else pd.DataFrame(columns=["timestamp","lat","lon"])
checkins = ensure_timestamp(checkins)

meds = pd.read_csv(MEDS_CSV) if os.path.exists(MEDS_CSV) else pd.DataFrame(columns=["name","interval_hours","start_time","notes"])
med_log = pd.read_csv(MEDLOG_CSV) if os.path.exists(MEDLOG_CSV) else pd.DataFrame(columns=["name","due_time","taken_at"])
if "taken_at" in med_log.columns:
    med_log["taken_at"] = pd.to_datetime(med_log["taken_at"], errors="coerce").dropna()

try:
    institutions = safe_read_csv(INSTITUTIONS_CSV) if os.path.exists(INSTITUTIONS_CSV) else pd.DataFrame()
except Exception:
    institutions = pd.DataFrame()
try:
    regional = safe_read_csv(REGIONAL_CSV) if os.path.exists(REGIONAL_CSV) else pd.DataFrame()
except Exception:
    regional = pd.DataFrame()

# ------------------------
# UI ê¸°ë³¸ ì„¤ì • (ê¸€ì í¬ê¸°)
# ------------------------
st.set_page_config(page_title="ğŸ§¡ ë…ê±°ë…¸ì¸ ì§€ì› ì›¹ì•± (Prototype)", page_icon="ğŸ§¡", layout="wide")
font_choice = st.sidebar.selectbox("ê¸€ì í¬ê¸°", ["ì†Œ","ì¼ë°˜","ëŒ€í˜•","ì´ˆëŒ€í˜•"], index=1)
_font_map = {"ì†Œ":"16px","ì¼ë°˜":"20px","ëŒ€í˜•":"24px","ì´ˆëŒ€í˜•":"30px"}
base_font = _font_map.get(font_choice, "20px")
st.markdown(f"""
<style>
:root {{ --base-font: {base_font}; }}
html, body, [class*="css"]  {{ font-size: var(--base-font); }}
button, .stButton>button {{ font-size: 1.05rem !important; padding: 0.5rem 0.9rem !important; border-radius: 10px !important; }}
.dog-img {{ width:260px; height:260px; border-radius:14px; cursor:pointer; }}
</style>
""", unsafe_allow_html=True)

st.title("ğŸ§¡ ë…ê±°ë…¸ì¸ ì§€ì› ì›¹ì•± (nurinuri_not_alone)")

# ------------------------
# íƒ­ (5ê°œ)
# ------------------------
tab1, tab2, tab3, tab4, tab5 = st.tabs(["â‘  ì²´í¬ì¸(ê°•ì•„ì§€)","â‘¡ ìœ„í—˜ë„/119 ì‹œë‚˜ë¦¬ì˜¤","â‘¢ ë³µì•½ ìŠ¤ì¼€ì¤„ëŸ¬","â‘£ ì£¼ë³€ ì˜ë£Œê¸°ê´€ ì°¾ê¸°","â‘¤ ë°ì´í„°/ì„¤ì •"])

# ------------------------
# â‘  ì²´í¬ì¸ (ê°•ì•„ì§€ í´ë¦­)
# ------------------------
with tab1:
    st.header("â‘  ë§¤ì¼ ì²´í¬ì¸ (ê°•ì•„ì§€ í„°ì¹˜)")
    st.markdown("ê°•ì•„ì§€ë¥¼ í„°ì¹˜í•˜ë©´ ì²´í¬ì¸ë©ë‹ˆë‹¤. (ìœ„ì¹˜ í—ˆìš© ì‹œ ë‚ ì”¨ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.)")

    # custom HTML component for dog image + geolocation
    dog_html = f"""
    <div style="text-align:center;">
      <img id="nuri_dog" src="{DOG_URL_IDLE}" class="dog-img" />
      <div style="font-size:14px;margin-top:8px;">ê°•ì•„ì§€ë¥¼ í„°ì¹˜í•˜ì„¸ìš” ğŸ¶</div>
      <script>
        const send = v => window.parent.postMessage({{type:"streamlit:setComponentValue", value:v}}, "*");
        const dog = document.getElementById("nuri_dog");
        dog.onclick = () => {{
          // visual feedback
          dog.style.transform = "scale(1.06) rotate(4deg)";
          setTimeout(()=>dog.style.transform="", 220);
          // try geolocation
          if (navigator.geolocation) {{
            navigator.geolocation.getCurrentPosition(function(pos){{
              send({{action:"checkin", lat: pos.coords.latitude, lon: pos.coords.longitude, ts: new Date().toISOString(), clicked:true}});
            }}, function(err){{
              send({{action:"checkin", lat:null, lon:null, ts: new Date().toISOString(), clicked:true}});
            }}, {{timeout:7000}});
          }} else {{
            send({{action:"checkin", lat:null, lon:null, ts: new Date().toISOString(), clicked:true}});
          }}
        }};
      </script>
    </div>
    """
    from streamlit.components.v1 import html as st_html
    comp_res = st_html(dog_html, height=380)

    # when JS posts, streamlit's component returns the posted dict as comp_res
    if comp_res is not None:
        if isinstance(comp_res, dict) and comp_res.get("action") == "checkin":
            lat = comp_res.get("lat"); lon = comp_res.get("lon")
            ts_raw = comp_res.get("ts")
            try:
                ts = pd.to_datetime(ts_raw)
                # localize if naive
                if ts.tzinfo is None:
                    ts = ts.replace(tzinfo=KST)
            except Exception:
                ts = now_kst()
            new = {"timestamp": ts, "lat": lat, "lon": lon}
            checkins = pd.concat([checkins, pd.DataFrame([new])], ignore_index=True)
            checkins["timestamp"] = pd.to_datetime(checkins["timestamp"], errors="coerce")
            save_csv(checkins, CHECKIN_CSV)
            # show success and weather via Open-Meteo if lat/lon present
            st.success(f"ì²´í¬ì¸ ì™„ë£Œ: {ts.astimezone(KST).strftime('%Y-%m-%d %H:%M:%S')}")
            if lat is not None and lon is not None:
                # Open-Meteo API (no key) - current weather
                try:
                    om_url = f"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}&current_weather=true&timezone=Asia%2FSeoul"
                    r = requests.get(om_url, timeout=6)
                    j = r.json()
                    cw = j.get("current_weather", {})
                    temp = cw.get("temperature")
                    wind = cw.get("winddirection")
                    weather_text = f"í˜„ì¬ ê¸°ì˜¨ {temp}Â°C"
                    st.info(f"í˜„ì¬ ìœ„ì¹˜ ë‚ ì”¨: {weather_text}")
                except Exception as e:
                    st.info("ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            else:
                st.info("ìœ„ì¹˜ ì •ë³´ ë¯¸í—ˆìš©: ìˆ˜ë™ ìœ„ì¹˜ ì„¤ì • ë˜ëŠ” ì§‘ ìœ„ì¹˜ ì‚¬ìš© ê°€ëŠ¥.")

    # recent checkins and hourly plot
    st.markdown("---")
    st.subheader("ìµœê·¼ ì²´í¬ì¸ ê¸°ë¡ ë° ì‹œê°„(ì‹œê°„ ë‹¨ìœ„)")
    if not checkins.empty:
        dfc = checkins.copy()
        dfc["timestamp"] = pd.to_datetime(dfc["timestamp"], errors="coerce")
        st.dataframe(dfc.sort_values("timestamp", ascending=False).head(50), use_container_width=True)
        df_plot = (dfc.assign(date=lambda x: pd.to_datetime(x["timestamp"]).dt.date,
                              hour_float=lambda x: pd.to_datetime(x["timestamp"]).dt.hour + pd.to_datetime(x["timestamp"]).dt.minute/60)
                        .sort_values("timestamp")
                        .groupby("date", as_index=False)["hour_float"].min()
                        .sort_values("date"))
        st.caption("ë‚ ì§œë³„ ì²« ì²´í¬ì¸ ì‹œê° (ì‹œê°„ ë‹¨ìœ„, ì†Œìˆ˜ì ì€ ë¶„ ë¹„ìœ¨)")
        if not df_plot.empty:
            st.line_chart(df_plot.set_index("date")["hour_float"])
    else:
        st.info("ì•„ì§ ì²´í¬ì¸ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")

# ------------------------
# â‘¡ ìœ„í—˜ë„/119 ì‹œë‚˜ë¦¬ì˜¤
# ------------------------
with tab2:
    st.header("â‘¡ ìœ„í—˜ë„ ì˜ˆì¸¡ ë° ìë™ ì•Œë¦¼(ì‹œë®¬ë ˆì´ì…˜)")
    leftc, rightc = st.columns([1,3])
    with leftc:
        risk_thr = st.slider("119/ë³´í˜¸ì ì—°ë½(ê°€ìƒ) ë°œë™ ê¸°ì¤€(%)", 10, 100, 60, 5)
        if st.button("ğŸ”” í…ŒìŠ¤íŠ¸ ì•Œë¦¼ìŒ ì¬ìƒ"):
            # play test alarm (user gesture)
            st.markdown(f'<audio autoplay controls src="data:audio/wav;base64,{ALARM_B64}"></audio>', unsafe_allow_html=True)
    with rightc:
        st.info("ìœ„í—˜ë„ëŠ” ìµœê·¼ ì²´í¬ì¸/ë³µì•½ ì´ë ¥ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°ë©ë‹ˆë‹¤. ì„ê³„ì¹˜ ì´ˆê³¼ ì‹œ ê°€ìƒ ê²½ë³´ê°€ ì‹¤í–‰ë©ë‹ˆë‹¤.")

    score, detail = risk_score(checkins, med_log, meds)
    st.subheader(f"í˜„ì¬ ìœ„í—˜ë„: {score}%")
    st.progress(min(1.0, score/100.0))
    c1,c2,c3 = st.columns(3)
    c1.metric("ìµœê·¼ 3ì¼ ê²°ì¸¡(ì¼)", detail["missing_last3"])
    c2.metric("ìµœê·¼ 7ì¼ ì´ìƒì¹˜(ì¼)", detail["outliers_last7"])
    c3.metric("ë³µì•½ ì¤€ìˆ˜(7ì¼)", f"{detail['adherence_7d']}%")

    if score >= risk_thr:
        st.error("âš ï¸ ìœ„í—˜ë„ ì„ê³„ì¹˜ ì´ˆê³¼! (ê°€ìƒ ê²½ë³´/ì—°ë½ ì‹œë‚˜ë¦¬ì˜¤)")
        # Try playing audio via autoplay HTML (may be blocked by browser)
        st.markdown(f'<audio autoplay controls src="data:audio/wav;base64,{ALARM_B64}"></audio>', unsafe_allow_html=True)
        st.markdown("""
**ì‹œë®¬ë ˆì´ì…˜: ìë™ ì—°ë½ ì ˆì°¨**
1) ë³´í˜¸ì 1ì°¨ ì—°ë½ ì‹œë„  
2) ë¯¸ì‘ë‹µ ì‹œ 119 ì—°ê³„ ì•ˆë‚´ ìŒì„± ì†¡ì¶œ  
3) ìœ„ì¹˜/ìµœê·¼ ì²´í¬ì¸/ë³µì•½ì •ë³´ ìš”ì•½ ì „ì†¡(ê°€ìƒ)
""")
    else:
        st.success("í˜„ì¬ëŠ” ì„ê³„ì¹˜ ë¯¸ë§Œì…ë‹ˆë‹¤.")

# ------------------------
# â‘¢ ë³µì•½ ìŠ¤ì¼€ì¤„ëŸ¬ / ë¦¬ë§ˆì¸ë”
# ------------------------
with tab3:
    st.header("â‘¢ ë³µì•½ ìŠ¤ì¼€ì¤„ëŸ¬ / ë¦¬ë§ˆì¸ë”")
    st.caption("ì•±ì´ ì—´ë ¤ ìˆì„ ë•Œì—ë§Œ ë¦¬ë§ˆì¸ë”ê°€ í™”ë©´ì— í‘œì‹œë©ë‹ˆë‹¤(í”„ë¡œí† íƒ€ì…).")

    with st.form("add_med", clear_on_submit=True):
        st.subheader("ì•½ ì¶”ê°€")
        cx, cy, cz = st.columns([2,1,2])
        name = cx.text_input("ì•½ ì´ë¦„", placeholder="ì˜ˆ: Warfarin")
        interval = cy.number_input("ë³µìš© ê°„ê²©(ì‹œê°„)", 1, 48, 12, 1)
        start_t = cz.text_input("ì²« ë³µìš© ì‹œê°(HH:MM)", "08:00")
        notes = st.text_input("ë©”ëª¨(ì„ íƒ)", "")
        submit = st.form_submit_button("ì¶”ê°€")
        if submit:
            if name and parse_time_str(start_t):
                meds = pd.concat([meds, pd.DataFrame([{"name": name, "interval_hours": int(interval), "start_time": start_t, "notes": notes}])], ignore_index=True)
                save_csv(meds, MEDS_CSV)
                st.success(f"ì•½ ì¶”ê°€ë¨: {name}")
                st.experimental_rerun()
            else:
                st.error("ì…ë ¥ì„ í™•ì¸í•˜ì„¸ìš”. (ì‹œê° í˜•ì‹ HH:MM)")

    if len(meds):
        st.subheader("ë“±ë¡ëœ ì•½")
        st.dataframe(meds, use_container_width=True)
    else:
        st.info("ë“±ë¡ëœ ì•½ì´ ì—†ìŠµë‹ˆë‹¤.")

    # due items
    due_items = due_now_list(meds, med_log, within_minutes=15, overdue_minutes=90)
    st.subheader("ë¦¬ë§ˆì¸ë”")
    if due_items:
        for idx, item in enumerate(due_items):
            name_i = item["name"]; due_dt = item["due_time"]
            due_txt = due_dt.astimezone(KST).strftime("%Y-%m-%d %H:%M")
            status = "ğŸ•’ ê³§ ë³µì•½" if item["status"]=="due" else "â° ì—°ì²´"
            st.warning(f"{status}: {name_i} / ì˜ˆì •ì‹œê° {due_txt}")
            b1,b2,_ = st.columns([1,1,3])
            with b1:
                if st.button(f"âœ… {name_i} ë³µìš© ê¸°ë¡", key=f"take_{idx}"):
                    med_log = pd.concat([med_log, pd.DataFrame([{"name": name_i, "due_time": due_dt, "taken_at": now_kst()}])], ignore_index=True)
                    save_csv(med_log, MEDLOG_CSV)
                    st.success(f"{name_i} ë³µìš© ê¸°ë¡ ì™„ë£Œ")
                    st.experimental_rerun()
            with b2:
                # attempt to play audio (user gesture recommended)
                st.markdown(f'<audio autoplay controls src="data:audio/wav;base64,{ALARM_B64}"></audio>', unsafe_allow_html=True)
            # show interactions
            inters = lookup_interactions(name_i)
            if inters:
                st.info("ë³µìš© ê´€ë ¨ ì£¼ì˜ì‚¬í•­:")
                for w in inters:
                    st.write(f"- {w}")
    else:
        st.success("í˜„ì¬ 15ë¶„ ì´ë‚´ ì˜ˆì •/ì—°ì²´ í•­ëª© ì—†ìŒ")

    st.markdown("---")
    st.subheader("ë³µìš© ê¸°ë¡")
    if not med_log.empty:
        st.dataframe(med_log.sort_values("taken_at", ascending=False).head(200), use_container_width=True)
    else:
        st.info("ë³µìš© ê¸°ë¡ ì—†ìŒ")

# ------------------------
# â‘£ ì£¼ë³€ ì˜ë£Œê¸°ê´€ ì°¾ê¸° ë° ì¶”ì²œ (ì „êµ­ ì§€ì›)
# ------------------------
with tab4:
    st.header("â‘£ ì£¼ë³€ ì•½êµ­/ë³‘ì› ì°¾ê¸° ë° ì¶”ì²œ (ì „êµ­ CSV ì§€ì›)")
    st.caption("ì „êµ­ ì˜ë£Œê¸°ê´€ CSVë¥¼ ì—…ë¡œë“œí•˜ë©´ lat/lon ì»¬ëŸ¼ì„ ì°¾ì•„ ë°˜ê²½ ë‚´ ê¸°ê´€ì„ ì¶”ì²œí•©ë‹ˆë‹¤.")

    inst_file = st.file_uploader("ì „êµ­ ì˜ë£Œê¸°ê´€ í‘œì¤€ë°ì´í„° CSV ì—…ë¡œë“œ", type=["csv"])
    if inst_file is not None:
        try:
            raw = safe_read_csv(inst_file)
            # normalize columns
            lat_col = None; lon_col = None
            for c in raw.columns:
                lc = c.lower()
                if lat_col is None and any(k in lc for k in ["ìœ„ë„","lat","latitude","y","ì¢Œí‘œy"]): lat_col = c
                if lon_col is None and any(k in lc for k in ["ê²½ë„","lon","lng","longitude","x","ì¢Œí‘œx"]): lon_col = c
            if lat_col and lon_col:
                raw = raw.rename(columns={lat_col:"lat", lon_col:"lon"})
                raw["lat"] = pd.to_numeric(raw["lat"], errors="coerce"); raw["lon"] = pd.to_numeric(raw["lon"], errors="coerce")
                # name col
                name_col = None
                for c in raw.columns:
                    if any(k in c.lower() for k in ["ëª…","name","ê¸°ê´€","ë³‘ì›","ì•½êµ­"]):
                        name_col = c; break
                if name_col: raw = raw.rename(columns={name_col:"name"})
                if "type" not in raw.columns:
                    raw["type"] = "ë³‘ì›"
                institutions = raw[[c for c in ["name","type","lat","lon","address"] if c in raw.columns]].copy()
                save_csv(institutions, INSTITUTIONS_CSV)
                st.success(f"ì—…ë¡œë“œ ì™„ë£Œ: {len(institutions)}ê°œ ê¸°ê´€ ì €ì¥")
            else:
                st.error("CSVì—ì„œ ìœ„ë„(lat)/ê²½ë„(lon) ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")

    # home location usage
    st.subheader("ê²€ìƒ‰ ìœ„ì¹˜ ì„¤ì •")
    home = load_home()
    use_home = st.checkbox("ì €ì¥ëœ ì§‘ ìœ„ì¹˜ ì‚¬ìš©", value=(home is not None))
    if use_home and home is not None:
        lat = float(home["lat"]); lon = float(home["lon"])
        st.success(f"ì§‘ ìœ„ì¹˜: {home['label']} ({lat:.6f}, {lon:.6f})")
        if st.button("ì§‘ ìœ„ì¹˜ ì‚­ì œ"):
            try:
                os.remove(HOME_JSON)
            except Exception:
                pass
            st.experimental_rerun()
    else:
        lat = st.number_input("ìœ„ë„(lat)", value=37.5665, format="%.6f")
        lon = st.number_input("ê²½ë„(lon)", value=126.9780, format="%.6f")
        if st.button("ì´ ìœ„ì¹˜ë¥¼ ì§‘ìœ¼ë¡œ ì €ì¥"):
            if save_home(lat, lon, "ìš°ë¦¬ ì§‘"):
                st.success("ì§‘ ìœ„ì¹˜ ì €ì¥ë¨")
                st.experimental_rerun()

    if not institutions.empty and {"lat","lon"}.issubset(institutions.columns):
        radius_km = st.slider("ê²€ìƒ‰ ë°˜ê²½(km)", 1, 100, 10)
        tsel = st.selectbox("ê¸°ê´€ ìœ í˜•", ["ì „ì²´","ë³‘ì›","ì•½êµ­"], index=0)
        df = institutions.copy()
        if tsel != "ì „ì²´":
            df = df[df["type"].str.contains(tsel, na=False)]
        df["distance_km"] = haversine_km(lat, lon, df["lat"].astype(float), df["lon"].astype(float))
        df = df[df["distance_km"] <= radius_km].sort_values("distance_km").reset_index(drop=True)
        if len(df):
            st.subheader("ê°€ê¹Œìš´ ìˆœ ì¶”ì²œ ë¦¬ìŠ¤íŠ¸")
            show_cols = [c for c in ["name","type","address","distance_km"] if c in df.columns]
            st.dataframe(df[show_cols].head(50), use_container_width=True)
            layers = [
                pdk.Layer("ScatterplotLayer", data=pd.DataFrame([{"name":"ì§‘","lat":lat,"lon":lon}]), get_position='[lon, lat]', get_radius=120, get_fill_color=[255,0,0,200]),
                pdk.Layer("ScatterplotLayer", data=df.head(200), get_position='[lon, lat]', get_radius=60, get_fill_color=[0,128,255,160])
            ]
            view_state = pdk.ViewState(latitude=lat, longitude=lon, zoom=11)
            st.pydeck_chart(pdk.Deck(layers=layers, initial_view_state=view_state))
        else:
            st.info("ë°˜ê²½ ë‚´ ê²°ê³¼ ì—†ìŒ.")
    else:
        st.info("ì˜ë£Œê¸°ê´€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. CSV ì—…ë¡œë“œ í›„ ì‹œë„í•˜ì„¸ìš”.")

# ------------------------
# â‘¤ ë°ì´í„°/ì„¤ì • (ë‹¤ìš´ë¡œë“œ/ì—…ë¡œë“œ + ìœ„í—˜ë„ ì ìˆ˜ì‹ ì„¤ëª…)
# ------------------------
with tab5:
    st.header("â‘¤ ë°ì´í„°/ì„¤ì • (ìë£Œ ê´€ë¦¬)")
    c1,c2,c3,c4 = st.columns(4)
    with c1:
        st.download_button("ì²´í¬ì¸ CSV", data=checkins.to_csv(index=False).encode("utf-8"), file_name="checkins.csv")
    with c2:
        st.download_button("ì•½ ëª©ë¡ CSV", data=meds.to_csv(index=False).encode("utf-8"), file_name="meds.csv")
    with c3:
        st.download_button("ë³µì•½ ê¸°ë¡ CSV", data=med_log.to_csv(index=False).encode("utf-8"), file_name="med_log.csv")
    with c4:
        if not institutions.empty:
            st.download_button("ì˜ë£Œê¸°ê´€ CSV", data=institutions.to_csv(index=False).encode("utf-8"), file_name="institutions.csv")
        else:
            st.write("ì˜ë£Œê¸°ê´€ CSV: (ì—†ìŒ)")

    st.markdown("---")
    st.markdown("#### ìë™ ë¡œë“œ ìƒíƒœ ë¯¸ë¦¬ë³´ê¸°")
    if os.path.exists("/mnt/data/ì „êµ­ì˜ë£Œê¸°ê´€ í‘œì¤€ë°ì´í„°.csv") or os.path.exists("ì „êµ­ì˜ë£Œê¸°ê´€ í‘œì¤€ë°ì´í„°.csv"):
        st.success("ì „êµ­ì˜ë£Œê¸°ê´€ ì›ë³¸ ê°ì§€ë¨(ìë™ ë³€í™˜ ê°€ëŠ¥)")
    if not institutions.empty:
        st.dataframe(institutions.head(10), use_container_width=True)
    else:
        st.info("ì˜ë£Œê¸°ê´€ ë°ì´í„° ì—†ìŒ")

    st.markdown("#### ìœ„í—˜ë„ ê³„ì‚°ì‹(ìš”ì•½)")
    st.code("""
# score = 0
# score += min(n_missing3, 3) / 3 * 40      # ìµœê·¼ 3ì¼ ê²°ì¸¡
# score += min(n_out7, 5) / 5 * 20          # ìµœê·¼ 7ì¼ ì´ìƒì¹˜(ì²´í¬ì¸ ì‹œê°)
# score += (1.0 - adherence) * 40           # 7ì¼ ë³µì•½ ì¤€ìˆ˜ìœ¨ ì—­ê°€ì¤‘
# => 0~100 ì ìˆ˜
""", language="python")

# ------------------------
# ìƒíƒœ ì €ì¥ (ì•± ì¢…ë£Œì‹œ)
# ------------------------
try:
    save_csv(checkins, CHECKIN_CSV)
    save_csv(meds, MEDS_CSV)
    save_csv(med_log, MEDLOG_CSV)
    if not institutions.empty: save_csv(institutions, INSTITUTIONS_CSV)
    if not regional.empty: save_csv(regional, REGIONAL_CSV)
except Exception:
    pass
